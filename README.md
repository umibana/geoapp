# Aplicaci√≥n Geoespacial Desktop (Electron + React + gRPC Python)

**Aplicaci√≥n de escritorio geoespacial moderna** construida con Electron que combina un frontend React con un backend Python gRPC. La aplicaci√≥n maneja procesamiento y visualizaci√≥n de datos geoespaciales con capacidades de **streaming ultra-responsivo** usando **comunicaci√≥n gRPC completamente auto-generada** y **formato de datos columnar eficiente**.

## üèóÔ∏è Arquitectura Moderna

### Stack Tecnol√≥gico Actual
- **Frontend**: Electron 36 + React 19 + TypeScript + Tailwind CSS 4 + shadcn/ui
- **Backend**: Servidor gRPC puro (Python) con generaci√≥n de datos numpy - sin Django/REST API
- **Comunicaci√≥n**: ‚úÖ **Sistema gRPC Completamente Auto-generado** via Protocol Buffers con IPC seguro de Electron
- **Formato de Datos**: ‚úÖ **Formato columnar** para 70% reducci√≥n de memoria y rendimiento √≥ptimo
- **Rendimiento**: ‚úÖ **Arquitectura de streaming dual** para datasets de 100K-5M+ puntos sin bloquear la UI
- **Generaci√≥n de Datos**: Generador numpy sint√©tico con datos geoespaciales (elevaci√≥n, temperatura, presi√≥n, ruido, ondas senoidales)
- **Testing**: Vitest (unit), Playwright (e2e), React Testing Library
- **Build**: Vite 6, Electron Forge, PyInstaller
- **Visualizaci√≥n**: ECharts para gr√°ficos scatter interactivos de alto rendimiento
- **Base de Datos**: SQLite para gesti√≥n de proyectos y datasets

### Patrones de Arquitectura Clave

1. **‚úÖ Sistema gRPC Completamente Auto-generado**: API completa con clientes, handlers, context bridges y tipos TypeScript generados autom√°ticamente desde archivos `.proto`
2. **‚úÖ Formato de Datos Columnar**: Estructura de arrays eficiente que reduce el uso de memoria en 70% comparado con formato de objetos
3. **‚úÖ Arquitectura de Procesamiento Dual**:
   - **Streaming Columnar**: Para 100K-2M puntos con API `getBatchDataColumnar/Streamed`
   - **Worker Threads**: Para 3M-5M+ puntos con procesamiento aislado y cach√© de datos de gr√°fico
4. **‚úÖ Comunicaci√≥n IPC Modular**: Sistema IPC organizado por dominios (backend, theme, window) con context bridges seguros
5. **‚úÖ Integraci√≥n Protocol Buffer**: Definiciones `.proto` como fuente √∫nica de verdad para TypeScript y Python
6. **‚úÖ Gesti√≥n de Procesos Desktop**: Servidor gRPC como ejecutable PyInstaller gestionado por el proceso principal de Electron
7. **‚úÖ Gesti√≥n de Proyectos**: Sistema completo de proyectos con almacenamiento SQLite y procesamiento de archivos CSV

### Flujo de Comunicaci√≥n
```
Componentes React (Proceso Renderer)
        ‚Üì Context Bridge Auto-generado (window.autoGrpc)
        ‚Üì IPC Seguro con Tipos Auto-generados
Proceso Principal (Handlers IPC Auto-generados)
        ‚îú‚îÄ‚îÄ Streaming Columnar (100K-2M puntos)
        ‚îî‚îÄ‚îÄ Worker Thread + Cach√© de Gr√°ficos (3M-5M+ puntos)
        ‚Üì Cliente gRPC Auto-generado (@grpc/grpc-js)
Servidor Python gRPC (puerto 50077)
        ‚îú‚îÄ‚îÄ Generador de Datos Numpy (columnar)
        ‚îú‚îÄ‚îÄ Procesamiento CSV con pandas
        ‚îî‚îÄ‚îÄ Base de Datos SQLite (proyectos)
```

## üöÄ API y M√©todos Disponibles

### Sistema Auto-generado (`window.autoGrpc`)
La aplicaci√≥n utiliza un **sistema completamente auto-generado** que elimina c√≥digo de API manual:

#### M√©todos Principales Disponibles
```typescript
// M√©todos de ejemplo simples
await window.autoGrpc.helloWorld({ message: "Hello!" });
await window.autoGrpc.echoParameter({ value: 42, operation: "square" });
await window.autoGrpc.healthCheck({});

// Datos geoespaciales
await window.autoGrpc.getFeatures({ bounds, feature_types: [], limit: 20 });

// ‚úÖ RECOMENDADO: Formato columnar para datasets grandes
await window.autoGrpc.getBatchDataColumnar({ 
  bounds, 
  data_types: ['elevation'], 
  max_points: 1000000, 
  resolution: 20 
});

// ‚úÖ RECOMENDADO: Streaming columnar para datasets ultra-grandes
await window.autoGrpc.getBatchDataColumnarStreamed({ 
  bounds, 
  data_types: ['elevation'], 
  max_points: 5000000, 
  resolution: 30 
}, (chunk) => {
  console.log(`Chunk ${chunk.chunk_number}/${chunk.total_chunks}: ${chunk.points_in_chunk} puntos`);
});

// Gesti√≥n de proyectos
await window.autoGrpc.createProject({ name: "Mi Proyecto", description: "Descripci√≥n" });
await window.autoGrpc.getProjects({ limit: 100, offset: 0 });

// Procesamiento de archivos CSV
await window.autoGrpc.analyzeCsv({ file_path: "/path/to/file.csv", rows_to_analyze: 2 });
await window.autoGrpc.sendFile({ 
  file_path, 
  x_variable: "lng", 
  y_variable: "lat", 
  z_variable: "elevation" 
});
```

### Arquitecturas de Procesamiento

#### 1. **Streaming Columnar** (100K-2M puntos) üü¢ RECOMENDADO
- **Componente**: `ChildProcessVisualization`
- **API**: `getBatchDataColumnarStreamed`
- **Ventajas**: Formato columnar eficiente, streaming por chunks de 25K puntos, 70% menos memoria
- **UI**: Tema verde, "Columnar Data Streaming"
- **Ideal para**: Datasets medianos a grandes con eficiencia garantizada

#### 2. **Worker Threads** (3M-5M+ puntos) üü£ ULTRA-RENDIMIENTO
- **Componente**: `WorkerThreadVisualization` 
- **Tecnolog√≠a**: Worker threads reales de Node.js + cach√© de datos de gr√°fico
- **Ventajas**: Procesamiento completamente aislado, maneja datasets ultra-grandes sin bloquear UI
- **UI**: Tema morado, "True Node.js Worker Threads"
- **Ideal para**: Datasets masivos que requieren m√°ximo rendimiento

### Tipos de Datos en el Sistema

#### üèóÔ∏è **Datos de Producci√≥n** (Flujo Principal)
El flujo principal del proyecto trabaja con **archivos CSV reales**:
- **Mapeo de Coordenadas**: Configuraci√≥n manual de columnas CSV a coordenadas `x`, `y`, `z`
- **Datos Reales**: Archivos cargados por usuarios con datos geoespaciales reales
- **Componentes**: `ProjectWorkflow` ‚Üí `ProjectManager` ‚Üí `EnhancedCsvProcessor` ‚Üí `DatasetViewer`

### C√≥mo A√±adir Nuevos M√©todos

#### Opci√≥n A: Auto-generado (Recomendado) ‚ö°
1. **Actualiza Protocol Buffers**: Edita archivos en `/protos/` (ej: `geospatial.proto`)
2. **Implementa Backend**: A√±ade m√©todo en `backend/grpc_server.py`
3. **Regenera C√≥digo**: Ejecuta `npm run generate:full-stack`
4. **Usa Inmediatamente**: `const result = await window.autoGrpc.nuevoMetodo({ params })`

**Ventajas**: Cero c√≥digo manual, tipos TypeScript autom√°ticos, seguridad completa

#### Opci√≥n B: Integraci√≥n con Worker Threads (Solo para datasets masivos)
1. Usa formato de streaming por chunks
2. Integra con `MainProcessWorker` para procesamiento pesado
3. Implementa progreso y cancelaci√≥n
4. Cach√© de datos de gr√°fico para UI responsive

**Cu√°ndo usar cada opci√≥n**:
- **Opci√≥n A**: Para cualquier m√©todo nuevo, datasets peque√±os/medianos, prototipado r√°pido
- **Opci√≥n B**: Solo para datasets de 3M+ puntos que requieren UI 100% responsive

## üîß **Ejemplo: Implementar Worker Threads para una Funci√≥n**

### Caso Pr√°ctico: Procesamiento de An√°lisis Estad√≠stico de CSV

Supongamos que queremos agregar un m√©todo que calcule estad√≠sticas avanzadas de un dataset CSV cargado:

#### 1. **Definir Protocol Buffer** (`protos/geospatial.proto`)
```protobuf
// Nuevo m√©todo para an√°lisis estad√≠stico
rpc AnalyzeDatasetStats(AnalyzeDatasetStatsRequest) returns (stream DatasetStatsChunk);

message AnalyzeDatasetStatsRequest {
  string dataset_id = 1;
  repeated string columns = 2;        // Columnas a analizar
  bool include_correlations = 3;      // Incluir correlaciones
  int32 chunk_size = 4;              // Tama√±o de chunk para processing
}

message DatasetStatsChunk {
  int32 chunk_number = 1;
  int32 total_chunks = 2;
  repeated ColumnStats column_stats = 3;
  repeated CorrelationPair correlations = 4;
  int32 processed_rows = 5;
  bool is_final_chunk = 6;
}

message ColumnStats {
  string column_name = 1;
  double mean = 2;
  double std_dev = 3;
  double min_value = 4;
  double max_value = 5;
  int32 valid_count = 6;
}

message CorrelationPair {
  string column_a = 1;
  string column_b = 2;
  double correlation = 3;
}
```

#### 2. **Implementar Backend gRPC** (`backend/grpc_server.py`)
```python
def AnalyzeDatasetStats(self, request, context):
    """An√°lisis estad√≠stico con streaming por chunks"""
    try:
        import pandas as pd
        import numpy as np
        
        dataset = self.db.get_dataset_by_id(request.dataset_id)
        if not dataset:
            context.set_code(grpc.StatusCode.NOT_FOUND)
            return
            
        # Obtener datos del dataset
        all_data = self.db.get_dataset_data_all(request.dataset_id)
        df = pd.DataFrame(all_data)
        
        # Procesar por chunks para datasets grandes
        chunk_size = request.chunk_size or 10000
        total_rows = len(df)
        total_chunks = (total_rows + chunk_size - 1) // chunk_size
        
        for chunk_idx in range(total_chunks):
            start_idx = chunk_idx * chunk_size
            end_idx = min(start_idx + chunk_size, total_rows)
            chunk_df = df.iloc[start_idx:end_idx]
            
            # Calcular estad√≠sticas para este chunk
            chunk_stats = []
            for col in request.columns:
                if col in chunk_df.columns:
                    col_data = pd.to_numeric(chunk_df[col], errors='coerce')
                    stats = geospatial_pb2.ColumnStats(
                        column_name=col,
                        mean=col_data.mean(),
                        std_dev=col_data.std(),
                        min_value=col_data.min(),
                        max_value=col_data.max(),
                        valid_count=col_data.count()
                    )
                    chunk_stats.append(stats)
            
            # Calcular correlaciones si se solicita
            correlations = []
            if request.include_correlations and chunk_idx == total_chunks - 1:
                # Solo en el √∫ltimo chunk calculamos correlaciones totales
                corr_matrix = df[request.columns].corr()
                for i, col_a in enumerate(request.columns):
                    for j, col_b in enumerate(request.columns):
                        if i < j:  # Evitar duplicados
                            corr = geospatial_pb2.CorrelationPair(
                                column_a=col_a,
                                column_b=col_b,
                                correlation=corr_matrix.loc[col_a, col_b]
                            )
                            correlations.append(corr)
            
            # Enviar chunk
            chunk_response = geospatial_pb2.DatasetStatsChunk(
                chunk_number=chunk_idx,
                total_chunks=total_chunks,
                column_stats=chunk_stats,
                correlations=correlations,
                processed_rows=end_idx,
                is_final_chunk=(chunk_idx == total_chunks - 1)
            )
            
            yield chunk_response
            
    except Exception as e:
        context.set_code(grpc.StatusCode.INTERNAL)
        context.set_details(str(e))
```

#### 3. **Regenerar C√≥digo Auto-generado**
```bash
npm run generate:full-stack
```

#### 4. **Implementar Handler con Worker Threads** (`src/helpers/ipc/backend/backend-listeners.ts`)
```typescript
import { MainProcessWorker } from '../../mainProcessWorker';

// A√±adir handler para an√°lisis estad√≠stico
ipcMain.handle('grpc-analyze-dataset-stats', async (event, request) => {
  const requestId = `stats-${Date.now()}-${Math.random()}`;
  
  try {
    // Crear worker para procesamiento pesado
    const worker = MainProcessWorker.getInstance();
    const processor = worker.startStreamingProcessor(requestId, (progress) => {
      // Enviar progreso al renderer
      event.sender.send('grpc-stats-progress', { requestId, ...progress });
    });
    
    // Configurar procesamiento de estad√≠sticas
    const statsAccumulator = {
      columnStats: new Map(),
      correlations: [],
      totalProcessed: 0
    };
    
    // Procesar stream desde backend
    await autoMainGrpcClient.analyzeDatasetStats(request, (chunk) => {
      // Procesar chunk en worker thread
      processor.postChunk({
        chunk_data: chunk,
        processing_type: 'statistics',
        metadata: {
          chunk_number: chunk.chunk_number,
          total_chunks: chunk.total_chunks,
          processed_rows: chunk.processed_rows
        }
      });
      
      // Acumular estad√≠sticas
      chunk.column_stats.forEach(stat => {
        const existing = statsAccumulator.columnStats.get(stat.column_name);
        if (existing) {
          // Combinar estad√≠sticas de m√∫ltiples chunks
          statsAccumulator.columnStats.set(stat.column_name, {
            ...existing,
            mean: (existing.mean * existing.valid_count + stat.mean * stat.valid_count) / (existing.valid_count + stat.valid_count),
            valid_count: existing.valid_count + stat.valid_count,
            min_value: Math.min(existing.min_value, stat.min_value),
            max_value: Math.max(existing.max_value, stat.max_value)
          });
        } else {
          statsAccumulator.columnStats.set(stat.column_name, stat);
        }
      });
      
      // Agregar correlaciones del √∫ltimo chunk
      if (chunk.is_final_chunk && chunk.correlations.length > 0) {
        statsAccumulator.correlations = chunk.correlations;
      }
      
      statsAccumulator.totalProcessed = chunk.processed_rows;
    });
    
    // Finalizar procesamiento
    const result = await processor.finalize();
    
    return {
      success: true,
      statistics: {
        columnStats: Array.from(statsAccumulator.columnStats.values()),
        correlations: statsAccumulator.correlations,
        totalProcessed: statsAccumulator.totalProcessed,
        processingTime: result.processingTime,
        performanceMetrics: result.performanceMetrics
      }
    };
    
  } catch (error) {
    console.error('‚ùå Error in stats analysis:', error);
    return {
      success: false,
      error: error.message
    };
  }
});
```

#### 5. **Exponer en Context Bridge** (`src/preload.ts`)
```typescript
// A√±adir al context bridge existente
contextBridge.exposeInMainWorld('grpc', {
  // ... m√©todos existentes
  
  analyzeDatasetStats: async (
    datasetId: string, 
    columns: string[], 
    options?: { includeCorrelations?: boolean; chunkSize?: number }
  ) => {
    return ipcRenderer.invoke('grpc-analyze-dataset-stats', {
      dataset_id: datasetId,
      columns,
      include_correlations: options?.includeCorrelations || false,
      chunk_size: options?.chunkSize || 10000
    });
  }
});
```

#### 6. **Usar en el Frontend** 
```typescript
// En un componente React (ej: DatasetViewer.tsx)
const runStatisticalAnalysis = async (datasetId: string, columns: string[]) => {
  setLoading(true);
  setProgress(0);
  
  // Configurar listener de progreso
  const progressListener = (event: any, data: any) => {
    if (data.requestId.startsWith('stats-')) {
      setProgress(data.percentage);
      console.log(`An√°lisis estad√≠stico: ${data.phase} - ${data.percentage.toFixed(1)}%`);
    }
  };
  
  window.electronAPI.on('grpc-stats-progress', progressListener);
  
  try {
    // Ejecutar an√°lisis con worker threads
    const result = await window.grpc.analyzeDatasetStats(datasetId, columns, {
      includeCorrelations: true,
      chunkSize: 25000
    });
    
    if (result.success) {
      console.log('üìä An√°lisis estad√≠stico completado:');
      console.log('Estad√≠sticas por columna:', result.statistics.columnStats);
      console.log('Correlaciones:', result.statistics.correlations);
      console.log(`Procesados ${result.statistics.totalProcessed} filas en ${result.statistics.processingTime}s`);
      
      // Actualizar UI con resultados
      setStatistics(result.statistics);
    } else {
      console.error('Error en an√°lisis:', result.error);
    }
    
  } catch (error) {
    console.error('Error ejecutando an√°lisis:', error);
  } finally {
    setLoading(false);
    window.electronAPI.removeListener('grpc-stats-progress', progressListener);
  }
};
```

### üéØ **Ventajas de este Enfoque**

1. **‚úÖ Worker Threads Reales**: Procesamiento completamente aislado, UI nunca se bloquea
2. **‚úÖ Streaming Incremental**: Progreso en tiempo real y cancelaci√≥n posible
3. **‚úÖ Escalable**: Maneja datasets de millones de filas sin problemas de memoria
4. **‚úÖ Type Safety**: Todo auto-generado desde Protocol Buffers
5. **‚úÖ Reutilizable**: El patr√≥n se puede aplicar a cualquier procesamiento pesado
6. **‚úÖ Memoria Eficiente**: Procesamiento por chunks evita cargar todo en memoria

### üìã **Cu√°ndo Usar Worker Threads**
- Datasets > 100K filas
- C√°lculos que toman > 2 segundos
- Operaciones que requieren progreso en tiempo real
- Funcionalidades que usuarios pueden querer cancelar

## üìÅ Estructura del Proyecto

```
üì¶ geospatialWebapp/
‚îú‚îÄ‚îÄ üóÇÔ∏è backend/                    # Backend Python gRPC
‚îÇ   ‚îú‚îÄ‚îÄ grpc_server.py             # Servidor gRPC principal (puerto 50077)
‚îÇ   ‚îú‚îÄ‚îÄ data_generator.py          # Generador de datos numpy columnar
‚îÇ   ‚îú‚îÄ‚îÄ database.py                # Gestor de base de datos SQLite
‚îÇ   ‚îú‚îÄ‚îÄ build_server.py            # PyInstaller para empaquetado
‚îÇ   ‚îú‚îÄ‚îÄ requirements.txt           # Dependencias Python (grpcio, numpy, pandas)
‚îÇ   ‚îî‚îÄ‚îÄ generated/                 # Stubs Protocol Buffer auto-generados
‚îú‚îÄ‚îÄ üóÇÔ∏è src/                        # Frontend Electron + React
‚îÇ   ‚îú‚îÄ‚îÄ main.ts                    # Proceso principal Electron
‚îÇ   ‚îú‚îÄ‚îÄ preload.ts                 # Context bridge (window.autoGrpc)
‚îÇ   ‚îú‚îÄ‚îÄ renderer.ts                # Entrada del renderer React
‚îÇ   ‚îú‚îÄ‚îÄ App.tsx                    # Componente React principal
‚îÇ   ‚îú‚îÄ‚îÄ üóÇÔ∏è components/             # Componentes React
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ GrpcDemo.tsx           # Demo principal con todos los ejemplos
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ChildProcessVisualization.tsx   # Streaming columnar (verde)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ WorkerThreadVisualization.tsx   # Worker threads (morado)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ProjectManager.tsx     # Gesti√≥n de proyectos
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ EnhancedCsvProcessor.tsx # Procesamiento CSV avanzado
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ui/                    # Componentes shadcn/ui
‚îÇ   ‚îú‚îÄ‚îÄ üóÇÔ∏è grpc-auto/             # üî• Sistema auto-generado (NO EDITAR)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ auto-grpc-client.ts    # Cliente gRPC para renderer
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ auto-ipc-handlers.ts   # Handlers IPC para main process
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ auto-main-client.ts    # Cliente gRPC para main process
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ auto-context.ts        # Context bridge auto-generado
‚îÇ   ‚îú‚îÄ‚îÄ üóÇÔ∏è helpers/               # Utilidades y helpers
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ backend_helpers.ts     # Gesti√≥n del proceso backend Python
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ mainProcessWorker.ts   # Worker threads para datasets masivos
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ipc/                   # Sistema IPC modular por dominios
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ backend/           # IPC para backend
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ theme/             # IPC para temas
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ window/            # IPC para ventana
‚îÇ   ‚îú‚îÄ‚îÄ üóÇÔ∏è generated/             # Stubs TypeScript de Protocol Buffers
‚îÇ   ‚îî‚îÄ‚îÄ üóÇÔ∏è pages/                 # P√°ginas de la aplicaci√≥n
‚îú‚îÄ‚îÄ üóÇÔ∏è protos/                    # üìã Definiciones Protocol Buffer (fuente √∫nica de verdad)
‚îÇ   ‚îú‚îÄ‚îÄ main_service.proto         # Servicio principal que combina todos
‚îÇ   ‚îú‚îÄ‚îÄ geospatial.proto          # Tipos y m√©todos geoespaciales + columnar
‚îÇ   ‚îú‚îÄ‚îÄ files.proto               # Procesamiento de archivos CSV
‚îÇ   ‚îî‚îÄ‚îÄ projects.proto            # Gesti√≥n de proyectos y datasets
‚îú‚îÄ‚îÄ üóÇÔ∏è scripts/                   # Scripts de generaci√≥n y utilidades
‚îÇ   ‚îú‚îÄ‚îÄ generate-full-stack.js    # üî• Generador principal auto-generado
‚îÇ   ‚îî‚îÄ‚îÄ generate-protos.js        # Generador b√°sico de Protocol Buffers
‚îî‚îÄ‚îÄ package.json                  # Dependencias y scripts npm
```

### üîë Archivos Clave
- **`protos/main_service.proto`**: Punto de entrada principal que define todos los servicios disponibles
- **`src/grpc-auto/`**: Directorio completamente auto-generado - contiene toda la l√≥gica de comunicaci√≥n gRPC
- **`backend/grpc_server.py`**: Implementaci√≥n del servidor gRPC con todos los m√©todos de negocio
- **`src/components/GrpcDemo.tsx`**: Componente principal que demuestra todas las capacidades de la aplicaci√≥n

## üíª Desarrollo

### Configuraci√≥n Inicial
```bash
npm install                       # Instalar dependencias frontend
npm run setup:backend            # Instalar dependencias Python en venv/
```

### Desarrollo Diario
```bash
npm run dev                       # üöÄ RECOMENDADO: Inicia todo (genera protos + backend + frontend)
```

### Comandos Individuales
```bash
# Aplicaci√≥n
npm start                         # Solo aplicaci√≥n Electron (genera protos autom√°ticamente)
npm run dev:backend              # Solo servidor gRPC Python (puerto 50077)

# Generaci√≥n de c√≥digo
npm run generate:full-stack      # üî• Regenera sistema auto-generado completo
npm run generate:protos          # Genera solo stubs b√°sicos de Protocol Buffers

# Testing
npm run test                     # Tests unitarios (Vitest)
npm run test:e2e                # Tests end-to-end (Playwright) - requiere app empaquetada
npm run test:all                # Todos los tests

# Build y empaquetado
npm run build:backend           # Construye ejecutable Python (PyInstaller)
npm run make                    # Crea distributables de la aplicaci√≥n (incluye backend)
npm run build:full             # Build backend + empaqueta aplicaci√≥n Electron

# Code quality
npm run lint                    # ESLint
npm run format                  # Prettier check
npm run format:write           # Prettier format
```

### Variables de Entorno Python
La aplicaci√≥n usa un entorno virtual Python en `venv/` para dependencias aisladas:
- **Desarrollo**: `source venv/bin/activate` (autom√°tico en scripts npm)
- **Dependencias**: grpcio‚â•1.73.0, numpy‚â•1.24.0, pandas‚â•1.5.0, protobuf‚â•6.30.0

## üöÄ Ejemplo de Uso Completo

```typescript
// Ejemplo en un componente React
import { useState } from 'react';

function MiComponente() {
  const [datos, setDatos] = useState(null);
  const [progreso, setProgreso] = useState(0);

  const cargarDatos = async () => {
    const bounds = {
      northeast: { latitude: 37.8, longitude: -122.3 },
      southwest: { latitude: 37.7, longitude: -122.5 }
    };

    try {
      // Para datasets grandes (recomendado)
      const resultado = await window.autoGrpc.getBatchDataColumnarStreamed({
        bounds,
        data_types: ['elevation', 'temperature'],
        max_points: 1000000,
        resolution: 25
      }, (chunk) => {
        // Callback de progreso en tiempo real
        const porcentaje = ((chunk.chunk_number + 1) / chunk.total_chunks) * 100;
        setProgreso(porcentaje);
        console.log(`Procesando chunk ${chunk.chunk_number + 1}/${chunk.total_chunks}`);
      });

      console.log(`‚úÖ Procesados ${resultado.length} chunks exitosamente`);
      setDatos(resultado);
      
    } catch (error) {
      console.error('Error cargando datos:', error);
    }
  };

  return (
    <div>
      <button onClick={cargarDatos}>Cargar Datos Geoespaciales</button>
      {progreso > 0 && <progress value={progreso} max={100} />}
      {datos && <p>Datos cargados: {datos.length} chunks</p>}
    </div>
  );
}
```

## üì¶ Empaquetado y Distribuci√≥n

### Build de Desarrollo
```bash
npm run dev                       # Desarrollo completo con hot reload
```

### Build de Producci√≥n
```bash
npm run build:backend            # 1. Construye ejecutable Python (PyInstaller)
npm run make                     # 2. Crea distributables de Electron (incluye backend)
```

**Notas**:
- El ejecutable Python se genera en `backend/dist/grpc-server`
- Electron Forge incluye autom√°ticamente el backend como recurso extra
- La aplicaci√≥n empaquetada es completamente portable (no requiere Python instalado)

## ‚ö° Caracter√≠sticas de Rendimiento

### Optimizaciones Implementadas
- **‚úÖ Formato Columnar**: 70% menos uso de memoria vs formato de objetos
- **‚úÖ Streaming por Chunks**: Procesa 5M+ puntos sin bloquear UI
- **‚úÖ Worker Threads Reales**: Procesamiento completamente aislado
- **‚úÖ Cach√© de Gr√°ficos**: Transferencia eficiente de datos de visualizaci√≥n
- **‚úÖ Compresi√≥n gRPC**: Transferencia optimizada de datos
- **‚úÖ Sampling Inteligente**: M√°ximo 10K puntos para gr√°ficos manteniendo representatividad

### Benchmarks T√≠picos
- **100K puntos**: ~0.5s (streaming columnar)
- **1M puntos**: ~2-3s (streaming columnar)
- **5M puntos**: ~8-12s (worker threads + cach√©)
- **UI Responsividad**: 100% mantenida en todos los casos

## üõ°Ô∏è Seguridad

### Medidas de Seguridad Implementadas
- **Context Isolation**: Habilitado en Electron para m√°xima seguridad
- **Secure IPC**: Toda comunicaci√≥n v√≠a context bridges seguros
- **Process Isolation**: Backend gRPC ejecuta en proceso separado
- **No Remote Access**: gRPC server solo acepta conexiones localhost
- **Type Safety**: Tipos TypeScript auto-generados previenen errores

## üîß Resoluci√≥n de Problemas

### Problemas Comunes

#### Backend no inicia
```bash
# Verificar Python y dependencias
source venv/bin/activate
python backend/grpc_server.py

# Reinstalar dependencias
npm run setup:backend
```

#### Errores de generaci√≥n de c√≥digo
```bash
# Limpiar y regenerar
npm run generate:full-stack
```

#### Tests E2E fallan
```bash
# Los tests E2E requieren app empaquetada
npm run make
npm run test:e2e
```

### Logs y Debugging
- **Backend**: Logs detallados en consola con emojis
- **Frontend**: DevTools de Electron con logs estructurados
- **gRPC**: Logs de conectividad y rendimiento
- **Worker Threads**: Logs de progreso y estad√≠sticas

## üìö Recursos Adicionales

### Documentaci√≥n T√©cnica
- **Protocol Buffers**: [protobuf.dev](https://protobuf.dev)
- **gRPC Python**: [grpc.io/docs/languages/python](https://grpc.io/docs/languages/python)
- **Electron**: [electronjs.org/docs](https://electronjs.org/docs)
- **React 19**: [react.dev](https://react.dev)

### Arquitectura de Referencias
- **Auto-Generated APIs**: Inspecciona `src/grpc-auto/` para entender el sistema
- **Protocol Buffers**: Revisa `protos/` para la definici√≥n completa de APIs
- **Backend Implementation**: Estudia `backend/grpc_server.py` para l√≥gica de negocio
- **Frontend Examples**: Analiza `src/components/GrpcDemo.tsx` para patrones de uso

## üìÑ Licencia
Apache License 2.0

